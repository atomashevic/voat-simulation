"""
generate_csvs.py - Extract User Posts and Thread Conversations

Takes posts.csv file generated by sim-stats.py and produces:
1. CSV files for randomly sampled users containing all their posts
2. Text files of complete thread conversations with nested formatting
"""

import pandas as pd
import random
import time
# Seed random with current time to ensure different selections on each run
random.seed(time.time())
import os
import argparse
import textwrap
from datetime import datetime

def load_posts_data(csv_path):
    """Load posts data from CSV file"""
    print(f"Loading posts data from {csv_path}...")
    df = pd.read_csv(csv_path)
    print(f"Loaded {len(df)} posts from {df['user_id'].nunique()} users")
    return df

def sample_users(df, num_users=10):
    """Sample random users from the dataframe who have 5+ posts with mixed content types"""
    # Find users with at least 5 total posts
    user_post_counts = df['user_id'].value_counts()
    active_users = user_post_counts[user_post_counts >= 5].index.tolist()

    # Filter for users who have both submissions and comments
    qualified_users = []
    for user_id in active_users:
        user_posts = df[df['user_id'] == user_id]
        has_root_post = any(user_posts['comment_to'] == -1)
        has_comment = any(user_posts['comment_to'] != -1)

        if has_root_post and has_comment:
            qualified_users.append(user_id)

    print(f"Found {len(qualified_users)} users with 5+ posts including both submissions and comments")

    # Sample users
    if len(qualified_users) <= num_users:
        return qualified_users
    return random.sample(qualified_users, num_users)

def create_user_csvs(df, user_ids, output_dir):
    """Create CSV files for each sampled user"""
    user_dir = os.path.join(output_dir, 'users')
    os.makedirs(user_dir, exist_ok=True)

    print(f"Generating CSV files for {len(user_ids)} users...")
    for user_id in user_ids:
        user_posts = df[df['user_id'] == user_id].copy()

        # Determine post type
        user_posts['post_type'] = 'root_post'
        user_posts.loc[user_posts['comment_to'] != -1, 'post_type'] = 'comment'

        # Select relevant columns
        output_cols = ['id', 'thread_id', 'comment_to', 'post_type',
                       'tweet', 'round', 'news_id', 'shared_from', 'image_id']

        # Create user CSV
        csv_path = os.path.join(user_dir, f'user_{user_id}.csv')
        user_posts[output_cols].to_csv(csv_path, index=False)

    return user_dir

def find_complete_threads(df, min_comments=3, num_threads=10, max_attempts=500):
    """Find thread IDs that have exactly one root post, valid news_id, and min_comments comments"""
    print("Analyzing threads for selection...")

    # Get all unique thread IDs
    all_thread_ids = df['thread_id'].unique()

    # Filter for valid threads with exactly one root post
    valid_threads = []
    attempts = 0

    for thread_id in all_thread_ids:
        # Safety check to prevent infinite processing
        attempts += 1
        if attempts > max_attempts:
            print(f"Warning: Reached maximum thread analysis attempts ({max_attempts})")
            break

        # Get all posts in this thread
        thread_posts = df[df['thread_id'] == thread_id]

        # Count root posts
        root_posts = thread_posts[thread_posts['comment_to'] == -1]

        if len(root_posts) != 1:
            # Skip threads with multiple or no root posts
            if len(root_posts) == 0:
                print(f"  Thread {thread_id}: No root posts found, skipping")
            else:
                print(f"  Thread {thread_id}: {len(root_posts)} root posts found, skipping")
            continue

        # Count comments
        comments = thread_posts[thread_posts['comment_to'] != -1]
        if len(comments) < min_comments:
            # Skip threads with too few comments
            continue

        # Check for valid news_id
        root_post = root_posts.iloc[0]
        news_id = root_post['news_id']

        # Check if news_id is valid (not NA, empty, null, etc.)
        if pd.notna(news_id) and str(news_id).strip() and str(news_id).lower() != 'null':
            try:
                # Try to convert to int to ensure it's a valid integer
                int(news_id)
                valid_threads.append(thread_id)

                # Provide feedback for long-running process
                if len(valid_threads) % 5 == 0:
                    print(f"  Found {len(valid_threads)} valid threads so far...")

                # Stop early if we have enough threads
                if len(valid_threads) >= num_threads * 5:  # Get 5x more threads to ensure good random selection
                    break
            except (ValueError, TypeError):
                continue

    print(f"Found {len(valid_threads)} valid threads with exactly one root post, {min_comments}+ comments, and valid news_id")

    if not valid_threads:
        print("Warning: No valid threads found. Check your data structure or adjust criteria.")
        return []

    if len(valid_threads) < num_threads:
        # If we don't have enough valid threads, return all we have
        return valid_threads

    # Otherwise, return num_threads random valid threads
    return random.sample(valid_threads, num_threads)

def format_timestamp(timestamp):
    """Format timestamp for better readability"""
    try:
        dt = datetime.fromtimestamp(timestamp)
        return dt.strftime("%Y-%m-%d %H:%M:%S")
    except:
        return str(timestamp)

def build_thread_structure(df, thread_id):
    """Build thread structure with hierarchical comments"""
    # Get all posts in this thread
    thread_df = df[df['thread_id'] == thread_id].copy()

    # Verify thread has exactly one root post
    root_posts = thread_df[thread_df['comment_to'] == -1]
    if len(root_posts) != 1:
        print(f"WARNING: Thread {thread_id} has {len(root_posts)} root posts")

        # If we have multiple root posts, prioritize the earliest one by round
        if len(root_posts) > 1:
            root_post = root_posts.sort_values('round').iloc[0]
            # Mark the others as non-root for display purposes
            non_root_indices = root_posts[root_posts['id'] != root_post['id']].index
            thread_df.loc[non_root_indices, 'comment_to'] = root_post['id']
            print(f"  - Treating post ID {root_post['id']} as the root post")
            print(f"  - Converting {len(non_root_indices)} other posts to comments")
        else:
            return f"ERROR: Thread {thread_id} has no root posts"
    else:
        # Get the root post (the normal case)
        root_post = root_posts.iloc[0]

    # Get all comments (anything not the root post)
    comments = thread_df[thread_df['id'] != root_post['id']].copy()

    # Build comment tree
    def build_comment_tree(parent_id, level=0, max_depth=10, processed_ids=None):
        # Initialize processed_ids set to track processed comments
        if processed_ids is None:
            processed_ids = set()

        # Prevent infinite recursion
        if level > max_depth:
            return [f"{' ' * 4 * level}[Maximum nesting depth reached]"]

        # Find direct replies to this post
        replies = comments[comments['comment_to'] == parent_id].sort_values('round')
        result = []

        for _, comment in replies.iterrows():
            # Skip if we've already processed this comment (avoid cycles)
            if comment['id'] in processed_ids:
                continue

            # Add to processed set
            processed_ids.add(comment['id'])

            # Format the comment with indentation based on level
            formatted_comment = format_comment(comment, level)
            result.append(formatted_comment)

            # Recursively add child comments
            child_comments = build_comment_tree(comment['id'], level + 1, max_depth, processed_ids)
            result.extend(child_comments)

        return result

    # Format a post or comment
    def format_comment(post, level=0):
        # Create appropriate indentation based on comment level
        indent = "    " * level

        # Check if this is actually a root post (comment_to == -1)
        is_root_post = post['comment_to'] == -1

        # Use different formatting for root post vs comments
        if is_root_post:
            # Root post formatting (only for actual root posts)
            user_info = f"User {post['user_id']} at Round {post['round']} [ROOT POST]:"
            indent_content = ""
        else:
            # Comment formatting with visual hierarchy
            branch = "│   " * (level-1) if level > 1 else ""
            if level > 1:
                pointer = "├── "
            else:
                pointer = "└── "
            user_info = f"{branch}{pointer}User {post['user_id']} at Round {post['round']}:"
            indent_content = "│   " * (level-1) + "    " if level > 1 else "    "

        # Wrap and indent the content
        body = post['tweet']
        if not isinstance(body, str):
            body = str(body)

        # Set wider width for better readability
        wrapped_body = textwrap.fill(
            body,
            width=90,
            initial_indent=indent_content + "    ",
            subsequent_indent=indent_content + "    "
        )

        return f"{user_info}\n{wrapped_body}"

    # Format the root post
    formatted_root = format_comment(root_post)

    # Build the thread content
    thread_content = [
        f"{'=' * 80}",
        f"THREAD ID: {thread_id}  |  NEWS ID: {root_post['news_id']}  |  ROUND: {root_post['round']}",
        f"COMMENT COUNT: {len(comments)}  |  TOTAL POSTS: {len(thread_df)}",
        f"{'-' * 80}",
        formatted_root
    ]

    # Add comments tree
    comment_tree = build_comment_tree(root_post['id'], processed_ids=set())
    thread_content.extend(comment_tree)

    # Use a single newline for a more compact and hierarchical view
    return "\n".join(thread_content)

def create_thread_txts(df, thread_ids, output_dir):
    """Create text files for complete threads with formatted conversations"""
    thread_dir = os.path.join(output_dir, 'threads')
    os.makedirs(thread_dir, exist_ok=True)

    if not thread_ids:
        print("Warning: No valid threads to process")
        return thread_dir

    print(f"Generating TXT files for {len(thread_ids)} threads...")
    successful_threads = 0

    for i, thread_id in enumerate(thread_ids):
        print(f"Processing thread {i+1}/{len(thread_ids)}: ID {thread_id}")
        thread_content = build_thread_structure(df, thread_id)

        # Check if thread generation failed
        if isinstance(thread_content, str) and thread_content.startswith("ERROR:"):
            print(f"  Skipping thread {thread_id}: {thread_content}")
            continue

        # Write to file
        txt_path = os.path.join(thread_dir, f'thread_{thread_id}.txt')
        with open(txt_path, 'w', encoding='utf-8') as f:
            f.write(thread_content)

        successful_threads += 1
        print(f"  Successfully wrote thread {thread_id} to {txt_path}")

    print(f"Successfully generated {successful_threads} thread files")
    return thread_dir

def main(csv_path, output_dir='output'):
    """Main processing function"""
    # Track previously used threads
    used_threads_file = os.path.join(os.path.dirname(output_dir), 'used_threads.txt')
    used_threads = set()

    # Load previously used threads if file exists
    if os.path.exists(used_threads_file):
        with open(used_threads_file, 'r') as f:
            for line in f:
                try:
                    used_threads.add(int(line.strip()))
                except ValueError:
                    pass
    print(f"Found {len(used_threads)} previously used threads")
    try:
        # Create output directory
        os.makedirs(output_dir, exist_ok=True)

        # Load data
        df = load_posts_data(csv_path)

        # Generate user CSVs
        user_ids = sample_users(df)
        user_dir = create_user_csvs(df, user_ids, output_dir)

        # Generate thread TXT files
        thread_ids = []  # Initialize thread_ids to an empty list
        try:
            thread_ids = find_complete_threads(df, min_comments=3, num_threads=10)
            thread_dir = create_thread_txts(df, thread_ids, output_dir)
        except Exception as e:
            print(f"Error during thread processing: {str(e)}")
            thread_dir = os.path.join(output_dir, 'threads')
            os.makedirs(thread_dir, exist_ok=True)

        # Print summary
        print("\nProcessing complete!")
        print(f"- User CSVs saved to: {user_dir}/")
        print(f"- Thread TXTs saved to: {thread_dir}/")
        print(f"\nGenerated {len(user_ids)} user CSV files and {len(thread_ids)} thread TXT files")

    except Exception as e:
        print(f"\nError during processing: {str(e)}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Extract user posts and thread conversations')
    parser.add_argument('csv_path', type=str, help='Path to posts.csv file')
    parser.add_argument('--output', '-o', type=str, default='output',
                        help='Output directory (default: output)')
    args = parser.parse_args()

    main(args.csv_path, args.output)
