#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Reddit Reputation Analysis Script

This script calculates dynamical reputation metrics for Reddit simulation data
using the dynrep module. It processes posts.csv files generated by the sim-stats.py
script and produces various reputation analytics and visualizations.

Note: In Reddit simulation data, 1 round = 1 hour, and 24 rounds = 1 day.
The reputation calculations and visualizations work on a daily basis.

Usage:
    python reddit_reputation.py path/to/posts.csv output_directory [--min-round MIN] [--max-round MAX]

Example:
    python reddit_reputation.py results/reddit-tech/posts.csv results/reddit-tech --min-round 0 --max-round 720
"""

import pandas as pd
import argparse
import os
import sys
import dynrep as dr
from datetime import datetime

def print_header(file_path):
    """Print script header with file info"""
    print(f"\n{'-'*60}")
    print(f"Reddit Reputation Analysis: {os.path.basename(file_path)}")
    print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'-'*60}\n")

def load_data(file_path):
    """Load Reddit simulation data and validate columns"""
    print(f"[1/4] Loading data from {file_path}...")
    try:
        posts_df = pd.read_csv(file_path)
        print(f"      Loaded {len(posts_df)} posts and comments")

        # Validate required columns
        required_columns = ['id', 'user_id', 'comment_to', 'round']
        missing_columns = [col for col in required_columns if col not in posts_df.columns]

        if missing_columns:
            print(f"Warning: Missing required columns: {', '.join(missing_columns)}")
            print(f"Available columns: {', '.join(posts_df.columns)}")
            print("Please check your data format.")
            sys.exit(1)

        # Check if we have a timestamp column or we'll generate one
        time_columns = ['created_utc', 'created_at', 'timestamp', 'time', 'created']
        has_time_column = any(col in posts_df.columns for col in time_columns)

        if not has_time_column:
            print("Note: No timestamp column found. Synthetic timestamps will be generated based on rounds.")

        return posts_df
    except Exception as e:
        print(f"Error loading data: {str(e)}")
        sys.exit(1)

def calculate_reputation(posts_df, output_dir, beta=0.96, alpha=2.0, Ib=1.0):
    """Calculate both popularity and engagement reputation"""
    # Use full dataset range, excluding news items (round = -1)
    simulation_data = posts_df[posts_df['round'] >= 0]
    actual_min_round = simulation_data['round'].min()
    max_round = simulation_data['round'].max() + 1
    
    # Normalize rounds to start from 0 (due to bug in post generation)
    posts_df_normalized = posts_df.copy()
    posts_df_normalized['round'] = posts_df_normalized['round'] - actual_min_round
    
    # Use normalized range: 0 to (max - min)
    min_round = 0
    max_round = max_round - actual_min_round
    
    # Convert rounds (hours) to days for display
    min_day = min_round // 24
    max_day = max_round // 24

    print(f"[2/4] Preparing data for reputation calculation...")
    print(f"      Time range: rounds {min_round} to {max_round} (hours)")
    print(f"                  days {min_day} to {max_day}")
    print(f"      Parameters: beta={beta}, alpha={alpha}, Ib={Ib}")

    # Prepare data for popularity reputation
    print(f"      Preparing popularity data...")
    pop_data = dr.prepare_reddit_interactions(posts_df_normalized, min_round, max_round, 'pop')

    # Prepare data for engagement reputation
    print(f"      Preparing engagement data...")
    eng_data = dr.prepare_reddit_interactions(posts_df_normalized, min_round, max_round, 'eng')

    print(f"[3/4] Calculating reputation metrics...")

    # Calculate popularity reputation
    pop_rep = None
    if not pop_data.empty:
        print(f"      Calculating popularity reputation...")
        try:
            pop_rep = dr.calculate_dynamical_reputation(pop_data, beta=beta, Ib=Ib, alpha=alpha, decay_per_day="True")
            print(f"      Calculated popularity reputation for {len(pop_rep)} users")

            # No need to apply threshold here as it's handled in dynrep.py
        except Exception as e:
            print(f"Error calculating popularity reputation: {str(e)}")
    else:
        print("      Skipping popularity reputation (no data)")

    # Calculate engagement reputation
    eng_rep = None
    if not eng_data.empty:
        print(f"      Calculating engagement reputation...")
        try:
            eng_rep = dr.calculate_dynamical_reputation(eng_data, beta=beta, Ib=Ib, alpha=alpha, decay_per_day="True")
            print(f"      Calculated engagement reputation for {len(eng_rep)} users")

            # No need to apply threshold here as it's handled in dynrep.py
        except Exception as e:
            print(f"Error calculating engagement reputation: {str(e)}")
    else:
        print("      Skipping engagement reputation (no data)")

    return pop_rep, eng_rep

def generate_visualizations(pop_rep, eng_rep, output_dir):
    """Generate reputation visualizations and export data"""
    print(f"[4/4] Generating visualizations and exporting data...")

    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Create reputation subdirectory
    reputation_dir = os.path.join(output_dir, 'reputation')
    os.makedirs(reputation_dir, exist_ok=True)

    # Generate popularity reputation visualizations
    if pop_rep is not None and not pop_rep.empty:
        print(f"      Generating popularity reputation visualizations...")
        pop_dir = os.path.join(reputation_dir, 'popularity')

        # Count active users (reputation >= 1) in the last day without modifying the data
        active_users = 0
        if pop_rep is not None and not pop_rep.empty:
            # Use the last column (most recent day) to count active users
            last_day = pop_rep.columns.max()
            # Apply threshold only for counting, not modifying original data
            active_users = (pop_rep[last_day] >= 1).sum()

        print(f"      Active users (popularity rep >= 1): {active_users} out of {len(pop_rep)}")
        dr.plot_reputation_statistics(pop_rep, 'popularity', pop_dir)
        dr.export_reputation_data(pop_rep, 'popularity', reputation_dir)

    # Generate engagement reputation visualizations
    if eng_rep is not None and not eng_rep.empty:
        print(f"      Generating engagement reputation visualizations...")
        eng_dir = os.path.join(reputation_dir, 'engagement')

        # Count active users (reputation >= 1) in the last day without modifying the data
        active_users = 0
        if eng_rep is not None and not eng_rep.empty:
            # Use the last column (most recent day) to count active users
            last_day = eng_rep.columns.max()
            # Apply threshold only for counting, not modifying original data
            active_users = (eng_rep[last_day] >= 1).sum()
        
        print(f"      Active users (engagement rep >= 1): {active_users} out of {len(eng_rep)}")
        dr.plot_reputation_statistics(eng_rep, 'engagement', eng_dir)
        dr.export_reputation_data(eng_rep, 'engagement', reputation_dir)

def main():
    parser = argparse.ArgumentParser(description='Calculate and visualize Reddit reputation metrics for full dataset range')
    parser.add_argument('posts_file', type=str, help='Path to the posts.csv file')
    parser.add_argument('output_dir', type=str, help='Directory to save results')
    parser.add_argument('--beta', type=float, default=0.96, help='Reputation decay parameter (default: 0.96)')
    parser.add_argument('--alpha', type=float, default=2.0, help='Cumulation parameter (default: 2.0)')
    parser.add_argument('--Ib', type=float, default=1.0, help='Basic interaction value (default: 1.0)')


    args = parser.parse_args()

    try:
        # Print header
        print_header(args.posts_file)

        # Load data
        posts_df = load_data(args.posts_file)

        # Create output directory if it doesn't exist
        os.makedirs(args.output_dir, exist_ok=True)

        # Calculate reputation using full dataset range
        try:
            pop_rep, eng_rep = calculate_reputation(
                posts_df,
                args.output_dir,
                beta=args.beta,
                alpha=args.alpha,
                Ib=args.Ib
            )
        except Exception as e:
            print(f"Error during reputation calculation: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.exit(1)

        # Generate visualizations
        try:
            generate_visualizations(pop_rep, eng_rep, args.output_dir)
        except Exception as e:
            print(f"Error generating visualizations: {str(e)}")
            import traceback
            traceback.print_exc()

        # Print completion message
        print(f"\nAnalysis complete!")
        print(f"Results saved to: {args.output_dir}/reputation/")
        print(f"\nPopularity Reputation: {len(pop_rep) if pop_rep is not None and not pop_rep.empty else 0} users")
        print(f"Engagement Reputation: {len(eng_rep) if eng_rep is not None and not eng_rep.empty else 0} users")

    except Exception as e:
        print(f"\nUnexpected error: {str(e)}")
        import traceback
        traceback.print_exc()

    print(f"\nCompleted at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main()
