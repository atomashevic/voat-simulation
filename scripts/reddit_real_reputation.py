#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Reddit Reputation Analysis Script

This script calculates dynamical reputation metrics for real Reddit data
using the dynrep module. It processes posts.csv files generated by the sim-stats.py
script and produces various reputation analytics and visualizations.

The reputation calculations and visualizations work on a daily basis.

Usage:
    python reddit_reputation.py path/to/posts.csv output_directory [--min-round MIN] [--max-round MAX]

Example:
    python reddit_reputation.py results/reddit-tech/posts.csv results/reddit-tech --min-round 0 --max-round 720
"""

import pandas as pd
import argparse
import os
import sys
import dynrep as dr
from datetime import datetime,timedelta,timezone
import numpy as np

def print_header(file_path):
    """Print script header with file info"""
    print(f"\n{'-'*60}")
    print(f"Reddit Reputation Analysis: {os.path.basename(file_path)}")
    print(f"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'-'*60}\n")

import pandas as pd



def prepare_reddit_real(interactions, ltlim=None, htlim=None, reputation="pop"):

## zezda "days", ubaci days kolonu u originalni pq file, pa probaj tako.
    pass

def load_data(file_path):
    """Load Reddit simulation data and validate columns"""
    print(f"[1/4] Loading data from {file_path}...")
    try:
        posts_df = pd.read_parquet(file_path)[['user_id','parent_user_id','publish_date']]
        print(f"      Loaded {len(posts_df)} posts and comments")

        # Validate required columns
        required_columns = ['user_id','parent_user_id','publish_date']
        missing_columns = [col for col in required_columns if col not in posts_df.columns]

        if missing_columns:
            print(f"Warning: Missing required columns: {', '.join(missing_columns)}")
            print(f"Available columns: {', '.join(posts_df.columns)}")
            print("Please check your data format.")
            sys.exit(1)

        # Check if we have a timestamp column or we'll generate one
        time_columns = ['created_utc', 'created_at', 'timestamp', 'time', 'created','publish_date']
        has_time_column = any(col in posts_df.columns for col in time_columns)

        if not has_time_column:
            print("Note: No timestamp column found. Synthetic timestamps will be generated based on rounds.")

        return posts_df
    
    except Exception as e:
        print(f"Error loading data: {str(e)}")
        sys.exit(1)


def calculate_user_reputation(dates, d_min, day_max, beta=0.999, Ib=1, alpha=2, decay_per_day = "True" ): 
    """Returns a dictionary of user's reputational values for each day

    Args:
        dates (DataFrame): Pandas DataFrame with timestamp and day columns.
        Each row is a single interaction by the same user.
        d_min (datetime): Date-time stamp of the first interaction: 'YYYY-MM-DDTHH:MM:SS.SSS'
        day_max (int): Upper limit for days after first interaction which are counted.
        beta (float, optional): Reputation decay parameter. Defaults to 0.999.
        Ib (float, optional): Basic reputational value of a single interaction. Defaults to 1.
        alpha (float, optional): Cumulation parameter. Defaults to 2.
        decay_per_day (str, optional): Perform decay in each day of inactivity? Defaults to "True".

    Returns:
        (dict): A dictionary of user's reputational values for each day
    """
    dates = dates.sort_values(by='Time')
    Ru = {}
    first_day = dates.iloc[0].days
    first_date = dates.iloc[0].Time
    if first_day > 0:
        for day in range(first_day):
            Ru[day] = 0.
    A = 1
    Ru[first_day] = Ib + Ib*alpha*(1.-1./(A+1))
    last_day = first_day
    last_activity_date = first_date
    last_activity_day = first_day
    for i in range(1,len(dates)):
        curr_day = dates.iloc[i].days
        curr_activity_date = dates.iloc[i].Time
        if curr_day > (last_day+1):
            for i in range(curr_day-last_day - 1):
                inactive_date = pd.to_datetime(d_min) + timedelta(days=int(last_day)+2)
                update_reputation_inactive(Ru, inactive_date, last_activity_date, last_activity_day,  last_day, beta=beta, decay_per_day = decay_per_day)
                last_day = last_day + 1
                A = 0
        A+=1
        update_reputation(Ru, A, curr_activity_date, last_activity_date, last_day, last_activity_day, curr_day, beta=beta,  Ib=Ib, alpha=alpha, decay_per_day=decay_per_day)
        last_activity_date = curr_activity_date
        last_activity_day = curr_day
        last_day = curr_day
    rest_days = day_max - last_day
    for i in range(rest_days):
        inactive_date = pd.to_datetime(d_min) + timedelta(days=int(last_day)+2)
        update_reputation_inactive(Ru, inactive_date, last_activity_date, last_activity_day,  last_day, beta=beta, decay_per_day = decay_per_day)
        last_day = last_day + 1
    return Ru

def update_reputation_inactive(R, inactive_date, last_activity_date, last_activity_day, last_day, beta=0.999, decay_per_day = 'True'):
    """Performs the decay of user's reputation during a period of inactivity.

    Args:
        R (dict): Dictionary of user's reputation which will be updated.
        inactive_date (datetime): Date-time stamp designating when the period of inactivity ends
        last_activity_date (datetime): Date-time stamp designating when the last recorded activity of user
        last_activity_day (int): Day in which last activity was recorded
        last_day (int): Last day for which reputation was previously updated
        beta (float, optional): Reputation decay parameter. Defaults to 0.999.
        decay_per_day (str, optional): Perform decay in each day of inactivity? Defaults to "True".
    """
    dt = ( pd.to_datetime(inactive_date) - pd.to_datetime(last_activity_date))/np.timedelta64(1,'D')
    if decay_per_day=='True':
        D = R[last_day]*np.power(beta, dt)
    else:
        D = R[last_activity_day]*np.power(beta, dt)  
    R[last_day+1] = D

def update_reputation(R, A, curr_date, last_activity_date, last_day, last_activity_day, curr_day, beta=0.999,  Ib=1, alpha=2, decay_per_day='True'):
    """Performs the decay of user's reputation during a period of inactivity.

    Args:
        R (dict): Dictionary of user's reputation which will be updated.
        A (int): Count of consecutive interactions within time-window frame
        curr_date (datetime): Date-time stamp of current activity when update function was called
        last_activity_date (datetime): Date-time stamp designating previous activity of the user
        last_activity_day (int): Day in which last activity was recorded
        last_day (int): Last day for which reputation was previously updated
        beta (float, optional): Reputation decay parameter. Defaults to 0.999.
        decay_per_day (str, optional): Perform decay in each day of inactivity? Defaults to "True".
    """
    dt = ( pd.to_datetime(curr_date) - pd.to_datetime(last_activity_date))/np.timedelta64(1,'D')
    In = Ib + Ib*alpha*(1.-1./(A+1))
    if (decay_per_day=='False') and (A==1):
        D = R[last_activity_day]*np.power(beta, dt)
    else:
        D = R[last_day]*np.power(beta, dt)
    y = R.get(curr_day, 0.)
    y = In+D
    R[curr_day] = y

def calculate_dynamical_reputation(interactions, beta=0.999, Ib=1., alpha=2, decay_per_day = "True"):
    """Calculate time series of dynamical reputation for each user given a set of interactions.
    This is a linear method and does not use parallel computing.

    Args:
        interactions (DataFrame): Pandas dataframe of merged interactions.
        The type of merged interactions determines the type of reputation (popularity or engagement)
        beta (float, optional): Reputation decay parameter. Defaults to 0.999.
        Ib (float, optional): Basic reputational value of a single interaction. Defaults to 1.
        alpha (float, optional): Cumulation parameter. Defaults to 2.
        decay_per_day (str, optional): Perform decay in each day of inactivity? Defaults to "True".

    Returns:
        (DataFrame): DF with values of reputation for each user (row) each day (column)
    """

    TReputation = {} 
    users = interactions['UserId'].unique()
    day_max = max(interactions['days'])
    d_min = min(interactions['Time'])
    for u in users:
        dates = interactions[interactions['UserId']==u][['Time', 'days']]
        Ru = calculate_user_reputation(dates, d_min, day_max, beta=beta, Ib=Ib, alpha=alpha, decay_per_day = decay_per_day )
        TReputation[int(u)] = Ru
    df = pd.DataFrame(TReputation).T    
    return df



def generate_visualizations(pop_rep, eng_rep, output_dir):
    """Generate reputation visualizations and export data"""
    print(f"[4/4] Generating visualizations and exporting data...")

    # Ensure output directory exists
    os.makedirs(output_dir, exist_ok=True)

    # Create reputation subdirectory
    reputation_dir = os.path.join(output_dir, 'reputation')
    os.makedirs(reputation_dir, exist_ok=True)

    # Generate popularity reputation visualizations
    if pop_rep is not None and not pop_rep.empty:
        print(f"      Generating popularity reputation visualizations...")
        pop_dir = os.path.join(reputation_dir, 'popularity')

        # Count active users (reputation >= 1) in the last day without modifying the data
        active_users = 0
        if pop_rep is not None and not pop_rep.empty:
            # Use the last column (most recent day) to count active users
            last_day = pop_rep.columns.max()
            # Apply threshold only for counting, not modifying original data
            active_users = (pop_rep[last_day] >= 1).sum()

        print(f"      Active users (popularity rep >= 1): {active_users} out of {len(pop_rep)}")
        dr.plot_reputation_statistics(pop_rep, 'popularity', pop_dir)
        dr.export_reputation_data(pop_rep, 'popularity', reputation_dir)

    # Generate engagement reputation visualizations
    if eng_rep is not None and not eng_rep.empty:
        print(f"      Generating engagement reputation visualizations...")
        eng_dir = os.path.join(reputation_dir, 'engagement')

        # Count active users (reputation >= 1) in the last day without modifying the data
        active_users = 0
        if eng_rep is not None and not eng_rep.empty:
            # Use the last column (most recent day) to count active users
            last_day = eng_rep.columns.max()
            # Apply threshold only for counting, not modifying original data
            active_users = (eng_rep[last_day] >= 1).sum()
        
        print(f"      Active users (engagement rep >= 1): {active_users} out of {len(eng_rep)}")
        dr.plot_reputation_statistics(eng_rep, 'engagement', eng_dir)
        dr.export_reputation_data(eng_rep, 'engagement', reputation_dir)

def calculate_reputation(interactions, output_dir, beta=0.96, alpha=2.0, Ib=1.0):
    """Calculate both popularity and engagement reputation"""
    # Use full dataset range, excluding news items (round = -1)
    '''     day_max = max(posts_df['days'])
    day_min = min(posts_df['days'])

    posts_df_normalized = posts_df.copy()
    posts_df_normalized['days'] = posts_df_normalized['days'] - actual_min_round
    

    print(f"[2/4] Preparing data for reputation calculation...")
    print(f"      Time range: rounds {d_min} to {day_max} (hours)")
    print(f"                  days {d_min} to {day_max}")
    print(f"      Parameters: beta={beta}, alpha={alpha}, Ib={Ib}")

    '''
    day_max = max(interactions['days'])
    day_min = min(interactions['Time'])

    # Prepare data for popularity reputation
    print(f"      Preparing popularity data...")
    pop_data = prepare_reddit_real(interactions, day_min, day_max, 'pop')

    # Prepare data for engagement reputation
    print(f"      Preparing engagement data...")
    eng_data = prepare_reddit_real(interactions, day_min, day_max, 'eng')

    print(f"[3/4] Calculating reputation metrics...")

    # Calculate popularity reputation
    pop_rep = None
    if not pop_data.empty:
        print(f"      Calculating popularity reputation...")
        try:
            pop_rep = calculate_dynamical_reputation(pop_data, beta=beta, Ib=Ib, alpha=alpha, decay_per_day="True")
            print(f"      Calculated popularity reputation for {len(pop_rep)} users")

            # No need to apply threshold here as it's handled in dynrep.py
        except Exception as e:
            print(f"Error calculating popularity reputation: {str(e)}")
    else:
        print("      Skipping popularity reputation (no data)")

    # Calculate engagement reputation
    eng_rep = None
    if not eng_data.empty:
        print(f"      Calculating engagement reputation...")
        try:
            eng_rep = calculate_dynamical_reputation(eng_data, beta=beta, Ib=Ib, alpha=alpha, decay_per_day="True")
            print(f"      Calculated engagement reputation for {len(eng_rep)} users")

            # No need to apply threshold here as it's handled in dynrep.py
        except Exception as e:
            print(f"Error calculating engagement reputation: {str(e)}")
    else:
        print("      Skipping engagement reputation (no data)")

    return pop_rep, eng_rep


def main():
    parser = argparse.ArgumentParser(description='Calculate and visualize Reddit reputation metrics for full dataset range')
    parser.add_argument('posts_file', type=str, help='Path to the posts.pq file')
    parser.add_argument('output_dir', type=str, help='Directory to save results')
    parser.add_argument('--beta', type=float, default=0.96, help='Reputation decay parameter (default: 0.96)')
    parser.add_argument('--alpha', type=float, default=2.0, help='Cumulation parameter (default: 2.0)')
    parser.add_argument('--Ib', type=float, default=1.0, help='Basic interaction value (default: 1.0)')


    args = parser.parse_args()

    interactions = prepare_reddit_real("/home/socio/ysocial-simulations/MADOC/reddit-technology/sample_1/technology_sample_1.parquet")
    print(interactions.head())
    print(interactions["days"].describe())

    try:
        # Print header
        print_header(args.posts_file)

        # Load data
        posts_df = load_data(args.posts_file)

        # Create output directory if it doesn't exist
        os.makedirs(args.output_dir, exist_ok=True)

        # Calculate reputation using full dataset range
        try:
            pop_rep, eng_rep = calculate_reputation(
                posts_df,
                args.output_dir,
                beta=args.beta,
                alpha=args.alpha,
                Ib=args.Ib
            )
        except Exception as e:
            print(f"Error during reputation calculation: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.exit(1)

        # Generate visualizations
        try:
            generate_visualizations(pop_rep, eng_rep, args.output_dir)
        except Exception as e:
            print(f"Error generating visualizations: {str(e)}")
            import traceback
            traceback.print_exc()

        # Print completion message
        print(f"\nAnalysis complete!")
        print(f"Results saved to: {args.output_dir}/reputation/")
        print(f"\nPopularity Reputation: {len(pop_rep) if pop_rep is not None and not pop_rep.empty else 0} users")
        print(f"Engagement Reputation: {len(eng_rep) if eng_rep is not None and not eng_rep.empty else 0} users")

    except Exception as e:
        print(f"\nUnexpected error: {str(e)}")
        import traceback
        traceback.print_exc()

    print(f"\nCompleted at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main()
